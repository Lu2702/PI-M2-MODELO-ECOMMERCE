# PROYECTO INTEGRADOR M2: MODELADO DE DATOS Y BASES DE DATOS RELACIONALES

## ğŸ§  Primer Avance â€“ Bases de datos relacionales

Esta primera pare del proyecto tiene como objetivo demostrar la configuraciÃ³n, modelado e integraciÃ³n de una base de datos relacional usando PostgreSQL y SQLAlchemy (ORM en Python), asÃ­ como la limpieza y transformaciÃ³n de los datos para futuras tareas analÃ­ticas. Este README explica paso a paso cÃ³mo replicar el proyecto, su estructura y justificaciÃ³n de cada componente.

Lo siguiente descrito corresponde al **primer avance**, en el cual se establecen las bases del modelado, integraciÃ³n de datos y una exploraciÃ³n. En futuras etapas se integrarÃ¡n nuevas herramientas y funcionalidades.

---

## ğŸŒ ConfiguraciÃ³n del Entorno de Trabajo

### 1. Requisitos previos

* Tener instalado:

  * Python >= 3.9
  * Docker y Docker Compose

### 2. Levantar la infraestructura con Docker

La conexiÃ³n a la base de datos y a las herramientas auxiliares (DBT, PgAdmin, Streamlit) se realiza a travÃ©s de contenedores Docker definidos en los siguientes archivos:

* `docker-compose.yml`: Define los servicios de PostgreSQL, PgAdmin, DBT y Streamlit.
* `Dockerfile`: Configura la imagen base para DBT y Streamlit.
* `.env`: Contiene las variables sensibles necesarias para la configuraciÃ³n.

### 3. Variables de entorno (.env)

Crea un archivo ubicado en `mi_proyecto_pg/.env`, que contenga:

- âš ï¸ Importante: El archivo .env no estÃ¡ incluido por seguridad. Usa .env.example como plantilla y reemplaza con tus valores reales. Este archivo define las credenciales necesarias para conectarse a PostgreSQL y acceder a PgAdmin desde http://localhost:8080.

```
# Variables para PostgreSQL
POSTGRES_DB=postgres
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin123

# Variables para PgAdmin (REEMPLAZAR con tus datos reales)
PGADMIN_DEFAULT_EMAIL=tu_correo@ejemplo.com
PGADMIN_DEFAULT_PASSWORD=tu_contraseÃ±a_pgadmin
```

### 4. Levantar los contenedores

Desde la terminal, en la carpeta donde estÃ¡ el `docker-compose.yml`:

```bash
docker-compose up --build -d
```

Esto crea y levanta:

* Una base de datos PostgreSQL
* Un PgAdmin accesible desde `http://localhost:8080`
* Un contenedor con DBT
* Un contenedor con Streamlit (usado en fases posteriores)

---

## ğŸ“ Estructura del Proyecto

```
mi_proyecto_pg/
â”œâ”€â”€ .env                         # Variables para PostgreSQL y PgAdmin
â”œâ”€â”€ Dockerfile                   # Imagen para contenedor DBT
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de servicios Docker
â”œâ”€â”€ PRIMER AVANCE/              # ETL, ORM, scripts, modelo
â”‚   â”œâ”€â”€ db_conector.py
â”‚   â”œâ”€â”€ modelos.py
â”‚   â”œâ”€â”€ crear_tablas.py
â”‚   â”œâ”€â”€ 1.importar_usuarios.py
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ exploracion.ipynb        # se explica mÃ¡s adelante
â”‚   â””â”€â”€ DATA M2/                 # scripts .sql para extraer los datos
â”‚       â”œâ”€â”€ 2.usuarios.sql
â”‚       â”œâ”€â”€ 3.categorias.sql
â”‚       â”œâ”€â”€ 4.Productos.sql
â”‚       â”œâ”€â”€ 5.ordenes.sql
â”‚       â”œâ”€â”€ 6.detalle_ordenes.sql
â”‚       â”œâ”€â”€ 7.direcciones_envio.sql
â”‚       â”œâ”€â”€ 8.carrito.sql
â”‚       â”œâ”€â”€ 9.metodos_pago.sql
â”‚       â”œâ”€â”€ 10.ordenes_metodospago.sql
â”‚       â”œâ”€â”€ 11.resenas_productos.sql
â”‚       â””â”€â”€ 12.historial_pagos.sql
```

---

## ğŸš€ Paso a Paso para Ejecutar el Proyecto

### Paso 1: Crear las tablas con ORM

El archivo `crear_tablas.py` ejecuta el siguiente flujo:

1. Importa el motor de conexiÃ³n (`get_db_engine`) y el modelo base `Base` desde `db_conector.py`.
2. Importa todas las clases ORM desde `modelos.py` (Usuarios, Categorias, Productos, etc.).
3. Llama a `Base.metadata.create_all(bind=engine)` para crear todas las tablas en la base de datos conectada.
4. Imprime en consola un mensaje de Ã©xito o error.

Este enfoque asegura que las tablas estÃ©n definidas de manera centralizada y coherente con las clases Python del ORM.

**JustificaciÃ³n**:

* Evita errores manuales en definiciones SQL.
* Permite validar y reutilizar las estructuras en cualquier parte del cÃ³digo.
* Es ideal para entornos escalables y mantenibles.

### Paso 2: ImportaciÃ³n de datos desde archivos `.sql`

Los scripts como `1.importar_usuarios.py` utilizan expresiones regulares para extraer las sentencias `INSERT INTO` desde archivos `.sql` como `DATA M2/2.usuarios.sql`. Luego:

1. Se limpia el texto (por ejemplo, eliminando acentos).
2. Se separan los valores dentro del `VALUES (...)`.
3. Se insertan fila por fila como objetos ORM en la base de datos usando `session.add()` y `session.commit()`.

**Ventajas de este enfoque**:

* Se validan tipos, claves primarias y restricciones al momento de la inserciÃ³n.

### Paso 3: VerificaciÃ³n en PgAdmin

Una vez cargados los datos, se puede abrir `http://localhost:8080`, iniciar sesiÃ³n en PgAdmin con las credenciales del archivo `.env`, y:

* Explorar visualmente las tablas creadas por SQLAlchemy.
* Navegar por los datos cargados desde los archivos `.sql`.
* Realizar queries manuales para validaciÃ³n y anÃ¡lisis preliminar.

Esta visualizaciÃ³n es clave para asegurar que los datos estÃ¡n correctos, y para preparar futuros KPIs o modelos analÃ­ticos.

---

Esta parte del primer avance ya cuenta con:

* Base de datos relacional operativa en Docker.
* Tablas generadas automÃ¡ticamente vÃ­a ORM.
* Datos cargados desde archivos `.sql` por scripts ETL personalizados.
* ValidaciÃ³n visual mediante PgAdmin.

Con esta base, el proyecto estÃ¡ listo para avanzar hacia la exploraciÃ³n de los datos.

## ğŸ“Š AnÃ¡lisis Exploratorio y EvaluaciÃ³n de Calidad de Datos

El anÃ¡lisis exploratorio se realizÃ³ en el archivo `exploracion.ipynb`, utilizando una combinaciÃ³n de SQL, SQLAlchemy y herramientas grÃ¡ficas en Python como pandas, seaborn y matplotlib.

### ğŸ” Paso a paso del archivo `exploracion.ipynb`

1. **ConexiÃ³n a la base de datos**:

   * Se importa el engine desde `db_conector.py`
   * Se valida la conexiÃ³n exitosa

2. **CreaciÃ³n de sesiÃ³n SQLAlchemy**:

   * Se crea una sesiÃ³n con `sessionmaker()` para consultas ORM

3. **Carga de datos vÃ­a SQL**:

   * Se utiliza `pd.read_sql()` para obtener datos con consultas SQL
   * Se cargan tablas como `Usuarios`, `Productos`, `Carrito`, `ReseÃ±asProductos`, `HistorialPago`

4. **EvaluaciÃ³n de calidad de datos**:

   * `df.isnull().sum()` para detectar nulos
   * `df.duplicated() para verificar duplicados
   * ValidaciÃ³n de campos como emails (`@`) y precios no negativos

5. **Visualizaciones de distribuciÃ³n y comportamiento**:

   * DistribuciÃ³n de calificaciones
   * IntenciÃ³n de compra por mes (carrito)
   * MÃ©todos de pago mÃ¡s usados
   * Monto pagado por mes registrado en el historial

6. **ExtracciÃ³n de insights relevantes**:

   * Producto con mÃ¡s unidades agregadas al carrito
   * Top usuarios por ingreso
   * Productos mÃ¡s costosos y con mÃ¡s stock

---

### âœ… Verificaciones de Calidad

Se aplicaron revisiones sistemÃ¡ticas para garantizar la calidad e integridad de los datos:

* **Valores nulos**: Se usÃ³ `df.isnull().sum()` para cada tabla. **No se detectaron valores nulos** en ninguna columna clave.
* **Duplicados**: Se utilizÃ³ `df.duplicated()` y se confirmÃ³ que **no existÃ­an registros duplicados**.
* **Formato de correos electrÃ³nicos**: Se validÃ³ que todas las entradas en `Email` contuvieran el carÃ¡cter `@`.
* **Valores atÃ­picos**: Se inspeccionaron columnas como `Cantidad`, `Stock` y `MontoPagado` con estadÃ­sticos y boxplots.

> âœ… Resultado: **Los datos estÃ¡n en buen estado**, sin errores estructurales ni referenciales, y son adecuados para anÃ¡lisis, visualizaciÃ³n y modelado posterior.

---

## ğŸ“Œ Hallazgos Clave e Insights del AnÃ¡lisis Exploratorio

### ğŸ¯ Producto con mayor intenciÃ³n de compra

* **ProductoID 25** fue el que mÃ¡s veces se agregÃ³ al carrito: **338 unidades**.

### ğŸ‘¤ Top 5 usuarios con mayor ingreso generado (ordenes Completadas):

| UsuarioID | Ingreso Total USD |
| --------- | ----------------- |
| 112       | \$5,111.83        |
| 411       | \$4,905.19        |
| 703       | \$4,424.94        |
| 390       | \$4,104.38        |
| 667       | \$4,057.64        |

Esto permite identificar a usuarios de alto valor para posibles estrategias de fidelizaciÃ³n o segmentaciÃ³n personalizada.

### ğŸ’° Top 5 productos mÃ¡s caros del catÃ¡logo

| Producto                   | Precio Unitario USD |
| -------------------------- | ------------------- |
| Laptop Dell Inspiron 15    | \$799.00            |
| Consola PlayStation 5      | \$549.99            |
| Smartphone Galaxy A54      | \$349.99            |
| Bicicleta MontaÃ±a Aro 29   | \$299.00            |
| Auriculares Bluetooth Sony | \$129.99            |

La tabla muestra que los productos mÃ¡s caros del catÃ¡logo pertenecen principalmente a la categorÃ­a de tecnologÃ­a y tienen un alto valor unitario. Implementar una secciÃ³n en el e-commerce que recomiende productos complementarios cuando el usuario visualice o agregue al carrito uno de los productos premium.

### ğŸ“¦ Top 5 productos con mÃ¡s inventario disponible

| Producto                    | Unidades en Stock |
| --------------------------- | ----------------- |
| Cuaderno Universitario 100h | 300               |
| Alcohol en Gel 500ml        | 200               |
| Camiseta BÃ¡sica Hombre      | 200               |
| Crema Hidratante Facial     | 150               |
| Jeans Skinny Mujer          | 150               |

Esta informaciÃ³n es clave para estrategias de rotaciÃ³n de stock y campaÃ±as de liquidaciÃ³n.
Lanzar una campaÃ±a de promociÃ³n o liquidaciÃ³n dirigida a estos productos para acelerar su salida del inventario.

### ğŸ‘¥ Total de usuarios registrados

* Se detectaron **1,000 usuarios Ãºnicos**, lo que indica una buena base de clientes para anÃ¡lisis de comportamiento.

---

## ğŸ“ˆ Visualizaciones destacadas

* **Monto total pagado por mes**: El mes **abril** (4) fue el de mayor ingreso total con **\$469,415.61**.
* **DistribuciÃ³n de calificaciones**: Las evaluaciones estÃ¡n distribuidas de manera relativamente uniforme entre 1 y 5 estrellas.
* **MÃ©todos de pago mÃ¡s utilizados**: Se observa una distribuciÃ³n balanceada entre todas las formas de pago, con ligera preferencia por â€œCrÃ©dito en tiendaâ€.
* **IntenciÃ³n de compra**: Las unidades agregadas al carrito aumentaron en el mes 5, lo cual podrÃ­a asociarse a promociones o estacionalidad.

Estas visualizaciones se encuentran documentadas y generadas automÃ¡ticamente dentro del cuaderno `exploracion.ipynb`.

---

Con esta informaciÃ³n, el proyecto concluye el **primer avance** con:

* Datos estructurados, cargados y validados
* Tablas limpias y sin inconsistencias
* AnÃ¡lisis exploratorio completo
* Hallazgos relevantes para futuras decisiones de negocio y modelado avanzado

## ğŸ§  Segundo Avance â€“ Modelado de Datos Dimensional

## ğŸ“ Estructura del Proyecto

```
MI_PROYECTO_PG/
â”‚
â”œâ”€â”€ PROYECTO M2/
â”‚   â”œâ”€â”€ PRIMER AVANCE/
â”‚   â””â”€â”€ SEGUNDO AVANCE/
â”‚       â”œâ”€â”€ Conc_Carrito.drawio.png
â”‚       â”œâ”€â”€ Conc_DetalleOrdenes.drawio.png
â”‚       â”œâ”€â”€ Conc_Ordenes.drawio.png
â”‚       â”œâ”€â”€ Conc_OrdenesMetodosPago.drawio.png
â”‚       â”œâ”€â”€ Diagrama_ER.drawio.png
â”‚       â”œâ”€â”€ Log_Carrito.drawio.png
â”‚       â”œâ”€â”€ Log_DetalleOrdenes.drawio.png
â”‚       â”œâ”€â”€ Log_Ordenes.drawio.png
â”‚       â”œâ”€â”€ Log_OrdenesMetodosPago.drawio.png
â”‚       â””â”€â”€ segundo_avance.ipynb
```

### ğŸ” PI 1: AnÃ¡lisis de negocio y descubrimiento de requisitos

* Analizar las preguntas de negocio a la luz de los datos presentados en el punto anterior.
* Entender quÃ© quiere resolver el negocio y quÃ© datos estÃ¡n disponibles para ello.

Los stakeholders han definido las siguientes preguntas clave que reflejan las prioridades estratÃ©gicas del negocio:

1. **Â¿CuÃ¡l es la tasa de conversiÃ³n de usuarios que agregan productos al carrito y concretan una compra?**
2. **Â¿CuÃ¡l es el ingreso generado por mes y el ingreso total acumulado?**
3. **Â¿QuÃ© categorÃ­a de producto presenta mayores ingresos?**
4. **Â¿QuÃ© usuario genera los mayores ingresos?**
5. **Â¿CuÃ¡l es la tasa de cancelaciÃ³n de Ã³rdenes de compra?**

---

### ğŸ“€ PI 2: IdentificaciÃ³n de componentes del modelo dimensional

#### âœ… Hechos (medidas)

| AcciÃ³n            | Hecho (Tabla de Hechos) | Medidas                  |
| ----------------- | ----------------------- | ------------------------ |
| Agregar a carrito | Carrito                 | Cantidad                 |
| Pedidos           | Ordenes                 | Total                    |
| Orden de compra   | DetalleOrdenes          | Cantidad, PrecioUnitario |
| Montos pagados    | OrdenesMetodosPago      | MontoPagado              |

#### ğŸŒŸ Dimensiones

| DimensiÃ³n   | RelaciÃ³n                                                                |
| ----------- | ----------------------------------------------------------------------- |
| Usuarios    | CuÃ¡l de los usuarios realiza las compras, pagos, agrega a carrito, etc. |
| Productos   | QuÃ© productos se venden o se abandonan                                  |
| CategorÃ­as  | A quÃ© categorÃ­a pertenecen los productos                                |
| MetodosPago | InformaciÃ³n sobre mÃ©todos de pago                                       |

---

### ğŸ§± PI 3: DiseÃ±o del modelo de datos

* Se modelÃ³ una arquitectura dimensional tipo estrella siguiendo la metodologia kimball para consultas eficientes.
* Se elaboraron los siguientes diagramas:

  * `Diagrama_ER.drawio.png` (diagrama general entidad-relaciÃ³n).
  * `Conc_*.drawio.png`: esquemas conceptuales por tabla.
  * `Log_*.drawio.png`: esquemas lÃ³gicos por tabla.

---

### ğŸ”€ PI 4: Slowly Changing Dimensions (SCDs)

#### Tipo 2 (mantiene historial):

* `Usuarios`: Cambios en nombre, apellido, dni, email.
* `Productos`: Cambios en precio.
* `MetodosPago`: Cambios en nombre.

#### Tipo 1 (sobrescribe):

* `CategorÃ­as`: Cambios en nombre o descripcion.

---

### ğŸ“Ÿ PI 5: DocumentaciÃ³n y justificaciÃ³n del modelo

* El modelo estÃ¡ alineado a las necesidades del negocio.
* Las tablas de hechos agrupan informaciÃ³n clave para las mÃ©tricas.
* Las dimensiones permiten filtros y segmentaciones ricas para anÃ¡lisis.
* El uso de SCD garantiza trazabilidad temporal donde es necesario.

ğŸ“ Archivos relacionados:

* ğŸ“˜ Notebook: `segundo_avance.ipynb`
* ğŸ“Š Diagramas ER y por tabla: `Conc_*.drawio.png`, `Log_*.drawio.png`, `Diagrama_ER.drawio.png`

# ğŸ“Š Tercer Avance - Proyecto DBT E-commerce

Este repositorio contiene una **versiÃ³n limpia y desacoplada** del modelo dimensional para un sistema de e-commerce, diseÃ±ado con DBT, integrado con PostgreSQL y preparado para visualizaciÃ³n en Streamlit.

> âš ï¸ Esta versiÃ³n fue renombrada para evitar conflictos con contenedores existentes. Sigue cuidadosamente los pasos para que puedas ejecutarlo desde cero.

---

## ğŸ§± Estructura del Proyecto `TERCER AVANCE DBT/`

```
TERCER AVANCE DBT/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ ecommerce_project/
â”‚       â”œâ”€â”€ dbt_project_copia.yml        # â† Renombrar a dbt_project.yml
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ bronze/                  # Archivos de staging
â”‚       â”‚   â”œâ”€â”€ silver/                  # Transformaciones intermedias
â”‚       â”‚   â””â”€â”€ gold/                    # MÃ©tricas, KPIs y vistas finales
â”‚       â”œâ”€â”€ snapshots/                   # Para Slowly Changing Dimensions
â”‚
â”œâ”€â”€ dbt_profiles/
â”‚   â””â”€â”€ profiles_copia.yml               # â† Renombrar a profiles.yml
```

---

## ğŸ” Pasos para replicar el proyecto

1. **Clona el repositorio** o copia manualmente la carpeta `TERCER AVANCE DBT/`.

2. **Renombra los archivos necesarios:**

   | Archivo/Carpeta Actual                        | Renombrar como    |
   | --------------------------------------------- | ----------------- |
   | `app/ecommerce_project/dbt_project_copia.yml` | `dbt_project.yml` |
   | `dbt_profiles/profiles_copia.yml`             | `profiles.yml`    |

3. **Abre la terminal y navega al directorio del proyecto:**

```bash
cd app/ecommerce_project
```

4. **Verifica la conexiÃ³n y la configuraciÃ³n del entorno DBT:**

```bash
dbt debug
```

5. **Ejecuta los modelos en orden:**

```bash
dbt run
```
---

## âš™ï¸ ConfiguraciÃ³n del Perfil DBT (`profiles.yml`)

Este archivo debe colocarse en la carpeta `dbt_profiles/`. Contiene las credenciales necesarias para conectarse al contenedor de PostgreSQL:

```yaml
ecommerce_project:
  target: dev
  outputs:
    dev:
      type: postgres
      host: db
      user: admin
      password: admin123
      port: 5432
      dbname: EcommerceDB
      schema: public
      threads: 4
```
## ğŸ’ª Paso a paso: ImplementaciÃ³n en DBT

### 1. **Modelo Bronze (Staging)**

* Se importaron las tablas brutas desde PostgreSQL utilizando `source.yml`.
* Se crearon archivos `.sql` por cada tabla (e.g., `stg_usuarios.sql`, `stg_productos.sql`).
* En esta capa no se alteran los datos, sÃ³lo se renombran columnas, se manejan nulos evidentes y se normaliza formato.

### 2. **Modelo Silver (Modelo dimensional)**

* Se definieron dimensiones y hechos:

  * `dim_usuarios`, `dim_productos`, `dim_metodos_pago`, `dim_categorias`
  * `fct_carrito`, `fct_ordenes`, `fct_detalleordenes`, `fct_ordenes_metodos_pago`
* Se implementaron relaciones entre tablas mediante claves forÃ¡neas.

### 3. **ğŸ”„ ImplementaciÃ³n de Slowly Changing Dimensions (SCD)**

En este proyecto se definieron algunas dimensiones como SCD tipo 2 (Usuarios, MÃ©todos de Pago, Productos) y tipo 1 (Categorias). Sin embargo, **durante este avance**, como aÃºn no se habÃ­an producido cambios reales en las fuentes, la estructura generada fue la siguiente:

```sql
current_timestamp AS "FechaInicio",
NULL AS "FechaFin",
TRUE AS "Activo"
```

> Esto se realizÃ³ para simular el comportamiento de SCD hasta que se detectaran cambios.

Una vez existan cambios y se activen los snapshots, se deberÃ¡ modificar a:

```sql
dbt_valid_from AS "FechaInicio",
dbt_valid_to AS "FechaFin",
dbt_current_flag AS "Activo"
```

Y tambiÃ©n el `generate_surrogate_key` deberÃ¡ incluir `"dbt_valid_from"` como parte del hash:

```sql
{{ dbt_utils.generate_surrogate_key(["MetodoPagoID", "dbt_valid_from"]) }} AS MetodoPagoSK
```

---

### 4. **Modelo Gold (KPIs e insights)**

* Se construyeron modelos agregados para responder las preguntas de negocio:

  * Ingreso mensual y acumulado
  * Tasa de conversiÃ³n de carrito a compra
  * Tasa de cancelaciÃ³n de Ã³rdenes
  * Ingreso total por usuario
  * Ingreso total por categorÃ­a de producto

---

## ğŸ§¬ Storytelling: Insights Clave del Negocio

> ğŸ” A partir de los KPIs definidos, el modelo arroja resultados que permiten tomar decisiones estratÃ©gicas:

### 1. ğŸŒ Tasa de conversiÃ³n

* De los 996 usuarios que agregaron productos al carrito, 990 realizaron una compra.
* **Tasa de conversiÃ³n: 99.4%**. Esto indica una experiencia de usuario eficiente

### 2. ğŸ“ˆ Ingreso acumulado por mes

* Se observa un crecimiento sostenido en los ingresos:
* **Ingreso total acumulado: \$2,752,410.34**.
* Durante el anÃ¡lisis de los ingresos mensuales del e-commerce, se identificaron tres meses clave con picos de ingresos:

- Agosto 2024 ($ 249,113.38)
- Abril 2025 ($ 242,874.59)
- Diciembre 2024 ($ 231,544.10)

Estos hallazgos permiten diseÃ±ar campaÃ±as mÃ¡s agresivas en temporadas clave, mejorar la logÃ­stica en esos meses y anticiparse con estrategias de marketing estacional

### 3. ğŸ§ Tasa de cancelaciÃ³n

* De 10,000 Ã³rdenes generadas, 2,510 fueron canceladas.
* **Tasa de cancelaciÃ³n: 25.1%**, una cifra que merece investigaciÃ³n y acciÃ³n para reducirla.

### 4. ğŸ§± Usuarios con mayores ingresos

* Usuarios como **Marcia**, **Juan JosÃ©** y **Samu** han generado mÃ¡s de \$7,700 en ingresos individuales.
* Esto permite personalizar promociones para clientes premium.

### 5. ğŸ›ï¸ CategorÃ­as mÃ¡s rentables

* Las categorÃ­as con mayor ingreso:

  * **TecnologÃ­a y Gadgets**
  * **Juguetes y Juegos**
  * **Videojuegos**
* Esto justifica estrategias de stock y publicidad dirigidas a esas categorÃ­as.

---

## ğŸ” ConclusiÃ³n

El modelo dimensional implementado con DBT permite un acceso estructurado, limpio y eficiente a los datos del e-commerce, respondiendo preguntas de negocio de forma directa y fundamentada.
âœ… Este avance marca la consolidaciÃ³n del modelo fÃ­sico y su capacidad para responder a las preguntas de negocio planteadas, sentando la base para el dashboard final en el cuarto avance.

> En el siguiente avance se documentarÃ¡ el modelo con `dbt docs` y se integrarÃ¡ la visualizaciÃ³n con **Streamlit**.

# ğŸ“¦ Cuarto Avance DBT + Streamlit

En este cuarto avance se abordan las etapas PI1, PI2 y PI3, enfocadas en la implementaciÃ³n de tests automÃ¡ticos para validar la integridad de los datos, la generaciÃ³n de documentaciÃ³n tÃ©cnica navegable con DBT, y la presentaciÃ³n visual de hallazgos clave mediante tÃ©cnicas de storytelling con datos.

---

## ğŸ§± Estructura del Proyecto 
```
.
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/
â”‚   â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ marts/
â”‚   â””â”€â”€ snapshots/
â”œâ”€â”€ snapshots/
â”œâ”€â”€ streamlit/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ dbt_project.yml
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```
---
## ValidaciÃ³n y OptimizaciÃ³n con DBT 

### Tests automÃ¡ticos

Se implementaron los siguientes tests de integridad en los archivos `schema.yml`:

- **not_null** y **unique** en claves primarias (`UsuarioID`, `ProductoID`, etc.).
- **relationships** para claves forÃ¡neas como `"CategoriaID"` en la tabla Productos:
ejemplo
```yml
- name: '"CategoriaID"'
  description: CategorÃ­a a la que pertenece cada producto
  tests: 
    - not_null
    - relationships:
        to: source('src', 'Categorias')
        field: '"CategoriaID"'
```
âœ… ValidaciÃ³n de Datos con Tests AutomÃ¡ticos en DBT
Los tests son una herramienta esencial para asegurar la calidad de los datos y garantizar relaciones correctas entre tablas.

ğŸ§ª Tipos de tests implementados:

not_null: Verifica que los campos clave como IDs no contengan valores nulos.

unique: Asegura unicidad en identificadores.

relationships: Comprueba la integridad referencial entre claves primarias y forÃ¡neas.

ğŸ“‚ ImplementaciÃ³n:
Todos los tests estÃ¡n definidos en los archivos schema.yml 

â–¶ï¸ EjecuciÃ³n:

Para correr todos los tests automÃ¡ticos definidos en el proyecto:

```bash
dbt test
```
---

### Materializaciones

Se experimentÃ³ con distintas materializaciones (`view`, `table`, `incremental`). Se optÃ³ por:

- `view` para modelos de bronze.
- `table` para modelos silver y gold

## DocumentaciÃ³n Interactiva con DBT 

La documentaciÃ³n fue generada con:

```bash
dbt docs generate
dbt docs serve --port 8080 --hostÂ 0.0.0.0
```
### ğŸ§­ VisualizaciÃ³n del Flujo de Modelos y KPIs (DBT Docs)

A continuaciÃ³n se presentan diagramas exportados desde DBT Docs, los cuales muestran cÃ³mo fluye la transformaciÃ³n de datos desde las fuentes (src) hasta los KPIs construidos en el modelo dimensional.

Estos grÃ¡ficos evidencian la trazabilidad, dependencias y arquitectura modular implementada en el proyecto.

ğŸ”¹ KPI: CategorÃ­a con Mayor Ingreso

<p align="center">
  <img src="docs/kpi_categoria_mayor_ingreso.png" width="700"/>
  <br><em>Figura 1. Trazabilidad del KPI de categorÃ­a con mayor ingreso</em>
</p>

ğŸ”¹ KPI: Ingresos Mensuales

<p align="center"> <img src="docs/kpi_ingresos_mensuales.png" width="700"/> <br><em>Figura 2. Flujo de modelos para calcular los ingresos mensuales</em> </p>

ğŸ”¹ KPI: Tasa de CancelaciÃ³n

<p align="center"> <img src="docs/kpi_tasa_cancelacion.png" width="700"/> <br><em>Figura 3. Pipeline del KPI de tasa de cancelaciÃ³n</em> </p>

ğŸ”¹ KPI: Tasa de ConversiÃ³n desde Carrito

<p align="center"> <img src="docs/kpi_tasa_conversion_carrito.png" width="700"/> <br><em>Figura 4. RelaciÃ³n entre carritos y Ã³rdenes para tasa de conversiÃ³n</em> </p>

ğŸ”¹ KPI: Usuario con Mayor Ingreso

<p align="center"> <img src="docs/kpi_usuario_mayor_ingreso.png" width="700"/> <br><em>Figura 5. Estructura de modelos para identificar al usuario con mayor ingreso</em> </p>

---

## VisualizaciÃ³n y Storytelling con Streamlit (PI3)

### DescripciÃ³n de la app

La visualizaciÃ³n se desarrolla con Streamlit usando PostgreSQL como backend. El archivo `app.py` realiza la conexiÃ³n, consulta KPIs y despliega grÃ¡ficas interactivas.

#### ConstrucciÃ³n del contenedor

Con el `Dockerfile` se ejecuta la app vÃ­a:

```bash
docker build -t streamlit_app .
docker run -p 8501:8501 streamlit_app
```

#### Requisitos

Archivo `requirements.txt`:

```
streamlit
psycopg2-binary
pandas
plotly
```

---

## KPIs Visualizados

| KPI                            | Detalle |
|-------------------------------|---------|
| CategorÃ­a con mÃ¡s ingreso     | ğŸ† TecnologÃ­a y Gadgets, con mÃ¡s de \$353,783 |
| Ingresos mensuales            | Crecimiento sostenido; acumulado > \$2.7M |
| Tasa de cancelaciÃ³n           | 25.1%, lo que indica oportunidades de mejora |
| Tasa de conversiÃ³n            | Alta eficiencia con 99.4% de usuarios con carrito que compran |
| Usuarios con mayores ingresos | Top 5 usuarios generaron mÃ¡s de \$37,000 en ingresos |

---

## Storytelling: Hallazgos clave

ğŸ“– Storytelling: Hallazgos Clave del Negocio
Los anÃ¡lisis realizados a partir del modelo dimensional y visualizados en el dashboard de Streamlit permiten identificar patrones relevantes que impactan directamente en la estrategia comercial de la tienda:

ğŸ† 1. TecnologÃ­a domina en ingresos
La categorÃ­a TecnologÃ­a y Gadgets lidera las ventas con $353,783 generados. Este comportamiento sugiere una clara preferencia del mercado por productos tecnolÃ³gicos, lo cual representa una oportunidad de expansiÃ³n del catÃ¡logo y ofertas dirigidas a este segmento.

<p align="center"> <img src="docs/kpi_categoria_mayor_ingreso_tabla.png" width="1000"/> <br><em>Figura A. Tabla con ingresos por categorÃ­a</em> </p> <p align="center"> <img src="docs/kpi_categoria_mayor_ingreso_grafico.png" width="1000"/> <br><em>Figura B. GrÃ¡fico de barras: ingreso total por categorÃ­a</em> </p>

ğŸ“ˆ 2. Tendencia positiva de ingresos mensuales
Los ingresos muestran un crecimiento sostenido mes a mes, con un acumulado que supera los $2.7 millones. Esta evoluciÃ³n sugiere una adopciÃ³n creciente del canal digital, y permite proyectar escenarios de demanda futura. Se recomienda reforzar las estrategias actuales de marketing digital y promociones mensuales.

<p align="center"> <img src="docs/kpi_ingresos_mensuales_tabla.png" width="1000"/> <br><em>Figura C. Tabla de ingresos mensuales por mes</em> </p> <p align="center"> <img src="docs/kpi_ingresos_mensuales_grafico.png" width="1000"/> <br><em>Figura D. GrÃ¡fico de lÃ­neas con ingreso mensual y acumulado</em> </p>

ğŸ›ï¸ 3. ConversiÃ³n casi perfecta
La tasa de conversiÃ³n es excepcional: el 99.4% de los usuarios que agregan productos al carrito en estado "Completo" y "Enviado" y completan su compra. Este dato evidencia que la experiencia de usuario. Es clave mantener esta eficiencia y evitar cambios drÃ¡sticos en la interfaz que puedan romper este flujo.

<p align="center"> <img src="docs/kpi_tasa_cancelacion_tabla.png" width="1000"/> <br><em>Figura E. Tabla que muestra el nÃºmero de Ã³rdenes y cancelaciones</em> </p> <p align="center"> <img src="docs/kpi_tasa_cancelacion_grafico.png" width="1000"/> <br><em>Figura F. VisualizaciÃ³n de la tasa de cancelaciÃ³n vs Ã³rdenes completadas</em> </p>

â— 4. Riesgo latente en cancelaciones
Con una tasa de cancelaciÃ³n del 25.1%, existe una alerta operativa: 1 de cada 4 pedidos confirmados es cancelado posteriormente. Este dato puede deberse a problemas logÃ­sticos, falta de stock o errores en medios de pago. Se recomienda auditar el proceso post-venta para identificar y atacar las causas raÃ­z.

<p align="center"> <img src="docs/kpi_tasa_conversion_carrito_tabla.png" width="1000"/> <br><em>Figura G. Tabla que incluye usuarios con carritos creados y con Ã³rdenes realizadas, finalmente cual es el porcentaje de conversiÃ³n </em> </p> <p align="center"> <img src="docs/kpi_tasa_conversion_carrito_grafico.png" width="1000"/> <br><em>Figura H. VisualizaciÃ³n del porcentaje de conversiÃ³n desde carrito a compra</em> </p>

ğŸ¯ 5. ConcentraciÃ³n de ingresos en pocos usuarios
El top 5 de usuarios concentra mÃ¡s de $37,000 en ingresos, lo que representa una oportunidad para implementar programas de fidelizaciÃ³n, membresÃ­as premium o beneficios exclusivos que fomenten la recurrencia y retenciÃ³n de estos clientes clave.

<p align="center"> <img src="docs/kpi_usuario_mayor_ingreso_tabla.png" width="1000"/> <br><em>Figura I. Tabla con los usuarios que generan mayor ingreso</em> </p> <p align="center"> <img src="docs/kpi_usuario_mayor_ingreso_grafico.png" width="1000"/> <br><em>Figura J. GrÃ¡fico de barras con ingresos por usuario</em> </p>

---

Autor: Guadalupe Ramirez  
Bootcamp Data Engineer





